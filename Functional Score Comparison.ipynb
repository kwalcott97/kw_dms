{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2516a6bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/keith_tetrad\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a917b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8030b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace with the path to your folder containing CSV files\n",
    "# folder_path = '/Users/keith_tetrad/kw_dms/old_results/coverage_temp'\n",
    "\n",
    "# # Initialize an empty dictionary\n",
    "# coverage_dict = {}\n",
    "\n",
    "# # Iterate over each file in the folder\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith('.csv'):\n",
    "#         # Create the key for the dictionary (filename without '.csv')\n",
    "#         dict_key = filename[:-4]\n",
    "\n",
    "#         # Read the CSV file into a DataFrame\n",
    "#         df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "\n",
    "#         # Add the DataFrame to the dictionary\n",
    "#         coverage_dict[dict_key] = df\n",
    "\n",
    "# # # Print dictionary keys\n",
    "# # print(\"Dictionary keys:\")\n",
    "# # for key in coverage_dict.keys():\n",
    "# #     print(key)\n",
    "\n",
    "# # # Print the first few rows of each DataFrame\n",
    "# # for name, df in coverage_dict.items():\n",
    "# #     print(f\"\\nFirst few rows of DataFrame '{name}':\")\n",
    "# #     print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba973b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace with the path to your folder containing functional score CSV files\n",
    "folder_path = 'kw_dms/old_results/func_scores_temp'\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "func_scores_dict = {}\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Create the key for the dictionary (filename without '.csv')\n",
    "        dict_key = filename[:-4]\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "\n",
    "        # Add the DataFrame to the dictionary\n",
    "        func_scores_dict[dict_key] = df\n",
    "\n",
    "# # Print dictionary keys\n",
    "# print(\"Dictionary keys:\")\n",
    "# for key in func_scores_dict.keys():\n",
    "#     print(key)\n",
    "\n",
    "# # Print the first few rows of each DataFrame\n",
    "# for name, df in func_scores_dict.items():\n",
    "#     print(f\"\\nFirst few rows of DataFrame '{name}':\")\n",
    "#     print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d42a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your folder containing CSV files\n",
    "folder_path = 'kw_dms/old_results/barcode_counts_temp'\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "barcode_counts_dict = {}\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Create the key for the dictionary (filename without '.csv')\n",
    "        dict_key = filename[:-4]\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "\n",
    "        # Add the DataFrame to the dictionary\n",
    "        barcode_counts_dict[dict_key] = df\n",
    "\n",
    "for key, df in barcode_counts_dict.items():\n",
    "    # Check if 'count' column exists in the DataFrame\n",
    "    if 'count' in df.columns:\n",
    "        # Rename the 'count' column to include the key as a prefix\n",
    "        df = df.rename(columns={'count': f'{key}_count'})\n",
    "        barcode_counts_dict[key] = df\n",
    "        \n",
    "# # Print dictionary keys\n",
    "# print(\"Dictionary keys:\")\n",
    "# for key in barcode_counts_dict.keys():\n",
    "#     print(key)\n",
    "\n",
    "# # Print the first few rows of each DataFrame\n",
    "# for name, df in barcode_counts_dict.items():\n",
    "#     print(f\"\\nFirst few rows of DataFrame '{name}':\")\n",
    "#     print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1757e",
   "metadata": {},
   "source": [
    "Merge barcode counts with the functional effect dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f611447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {}\n",
    "\n",
    "for func_key in func_scores_dict.keys():\n",
    "    # Split the key into two parts\n",
    "    parts = func_key.split('-vs-')\n",
    "    if len(parts) == 2:\n",
    "        # Merge the first part\n",
    "        if parts[0] in barcode_counts_dict:\n",
    "            merged_df = pd.merge(func_scores_dict[func_key], barcode_counts_dict[parts[0]], on='barcode', how='inner')\n",
    "        else:\n",
    "            continue  # Skip if no matching key is found\n",
    "\n",
    "        # Merge the second part\n",
    "        if parts[1] in barcode_counts_dict:\n",
    "            merged_df = pd.merge(merged_df, barcode_counts_dict[parts[1]], on='barcode', how='inner')\n",
    "        \n",
    "        # Store the merged DataFrame in the new dictionary\n",
    "        merged_dict[func_key] = merged_df\n",
    "\n",
    "# # Print dictionary keys\n",
    "# print(\"Dictionary keys:\")\n",
    "# for key in merged_dict.keys():\n",
    "#     print(key)\n",
    "\n",
    "# # Print the first few rows of each DataFrame\n",
    "# for name, df in merged_dict.items():\n",
    "#     print(f\"\\nFirst few rows of DataFrame '{name}':\")\n",
    "#     print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_key = '4u8c_B2T1-vs-DMSO_B1T2'  # Replace 'your_key' with the actual key you want to use\n",
    "\n",
    "# # Access the DataFrame using the key\n",
    "# specific_df = merged_dict[key]\n",
    "\n",
    "# # Display the column names\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f876afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dataframes = {'4u8c': [], 'Both': [], 'C7': []}\n",
    "\n",
    "for df_name, df in merged_dict.items():\n",
    "    if df_name.startswith('4u8c'):\n",
    "        grouped_dataframes['4u8c'].append((df_name, df))\n",
    "    elif df_name.startswith('Both'):\n",
    "        grouped_dataframes['Both'].append((df_name, df))\n",
    "    elif df_name.startswith('C7'):\n",
    "        grouped_dataframes['C7'].append((df_name, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c15bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "merged_group_dict = {}\n",
    "\n",
    "for group, df_tuples in grouped_dataframes.items():\n",
    "    for (key1, df1), (key2, df2) in combinations(df_tuples, 2):\n",
    "        # Rename 'func_score' and 'func_score_var' columns\n",
    "        df1 = df1.rename(columns={\n",
    "            'func_score': f'{key1}_func_score',\n",
    "            'func_score_var': f'{key1}_func_score_var'\n",
    "        })\n",
    "        df2 = df2.rename(columns={\n",
    "            'func_score': f'{key2}_func_score',\n",
    "            'func_score_var': f'{key2}_func_score_var'\n",
    "        })\n",
    "\n",
    "        # Merge DataFrames pairwise\n",
    "        merged_df = pd.merge(df1, df2, on=['barcode', 'aa_substitutions', 'n_aa_substitutions', 'n_codon_substitutions'], how='outer')\n",
    "\n",
    "        # Immediately drop rows with NaNs in either of the func_score columns\n",
    "        func_score_cols = [col for col in merged_df.columns if '_func_score' in col]\n",
    "        merged_df.dropna(subset=func_score_cols, inplace=True)\n",
    "\n",
    "        # Process duplicate '_count' columns\n",
    "        count_columns_x = [col for col in merged_df.columns if col.endswith('_x') and '_count' in col]\n",
    "        count_columns_y = [col for col in merged_df.columns if col.endswith('_y') and '_count' in col]\n",
    "\n",
    "        for col_x, col_y in zip(count_columns_x, count_columns_y):\n",
    "            base_col = col_x.replace('_x', '')\n",
    "            merged_df[base_col] = merged_df[col_x].fillna(merged_df[col_y])\n",
    "            merged_df.drop(columns=[col_x, col_y], inplace=True)\n",
    "\n",
    "        # Store the merged DataFrame\n",
    "        merged_group_dict[f'{key1}-and-{key2}'] = merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90986070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specific_key = '4u8c_B2T1-vs-DMSO_B1T2-and-4u8c_B2T2-vs-DMSO_B1T1'  # Replace this with the actual key you want to use\n",
    "\n",
    "# # Access the DataFrame using the key\n",
    "# specific_df = merged_group_dict[specific_key]\n",
    "\n",
    "# # Display the column names\n",
    "# print(specific_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23b8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "for key, df in merged_group_dict.items():\n",
    "    # Filter out '_func_score_var' columns and select only '_func_score' columns\n",
    "    func_score_columns = [col for col in df.columns if col.endswith('_func_score') and not col.endswith('_func_score_var')]\n",
    "    \n",
    "    # Increase plot size\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Create the scatter plot with a linear regression line\n",
    "    sns.regplot(x=func_score_columns[0], y=func_score_columns[1], data=df, scatter_kws={'alpha': 0.5}, line_kws={'color': 'black'})\n",
    "\n",
    "    # Calculate and annotate the R^2 value\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(df[func_score_columns[0]], df[func_score_columns[1]])\n",
    "    plt.annotate(f'$R^2$: {r_value**2:.2f}', xy=(0.05, 0.95), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(func_score_columns[0])\n",
    "    plt.ylabel(func_score_columns[1])\n",
    "    plt.title(f'Linear Regression of Func Scores for {key}')\n",
    "\n",
    "    # Remove grid lines\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Show or save the plot\n",
    "    plt.show()\n",
    "    # Uncomment to save the plot instead of showing it\n",
    "    # plt.savefig(f'{key}_scatter_plot.png')\n",
    "\n",
    "    # Close the plot to avoid overlapping plots in the next iteration\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n_selections_optimized(df, threshold):\n",
    "    # Filter for non-DMSO count columns\n",
    "    non_dmso_count_cols = [col for col in df.columns if '_count' in col and 'DMSO' not in col]\n",
    "\n",
    "    # Use vectorized comparison and sum across rows\n",
    "    df['n_selections'] = (df[non_dmso_count_cols] >= threshold).sum(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "threshold = 10\n",
    "for key in merged_group_dict:\n",
    "    merged_group_dict[key] = calculate_n_selections_optimized(merged_group_dict[key], threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbc879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Define colors for n_selections\n",
    "palette = {0: 'grey', 1: 'red', 2: 'blue'}\n",
    "\n",
    "for key, df in merged_group_dict.items():\n",
    "    # Filter out '_func_score_var' columns and select only '_func_score' columns\n",
    "    func_score_columns = [col for col in df.columns if col.endswith('_func_score') and not col.endswith('_func_score_var')]\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    df_clean = df.dropna(subset=func_score_columns)\n",
    "\n",
    "    # Define a new column for point style based on n_aa_substitutions\n",
    "    df_clean['style'] = df_clean['n_aa_substitutions'].apply(lambda x: 'variant' if x > 0 else 'WT')\n",
    "\n",
    "    # Increase plot size\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Create the scatter plot with a linear regression line in black\n",
    "    sns.regplot(x=func_score_columns[0], y=func_score_columns[1], data=df_clean, line_kws={'color': 'black'}, scatter=False)\n",
    "\n",
    "    # Create the scatter plot with color by n_selections and style by n_aa_substitutions\n",
    "    sns.scatterplot(x=func_score_columns[0], y=func_score_columns[1], data=df_clean, hue='n_selections', style='style', palette=palette, markers={'variant': 'X', 'WT': 'o'}, alpha=0.5)\n",
    "\n",
    "    # Calculate and annotate the R^2 value\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(df_clean[func_score_columns[0]], df_clean[func_score_columns[1]])\n",
    "    plt.annotate(f'$R^2$: {r_value**2:.2f}', xy=(0.05, 0.95), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(func_score_columns[0])\n",
    "    plt.ylabel(func_score_columns[1])\n",
    "    plt.title(f'Linear Regression of Func Scores for {key}')\n",
    "\n",
    "    # Remove grid lines\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Adjust legend position and combine legends for hue and style\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    n_selection_handles = handles[:len(palette)]\n",
    "    n_selection_labels = labels[:len(palette)]\n",
    "    style_handles = handles[len(palette):]\n",
    "    style_labels = labels[len(palette):]\n",
    "    plt.legend(n_selection_handles + style_handles, n_selection_labels + style_labels, title='n_selections & Style', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    # Show or save the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Close the plot to avoid overlapping plots in the next iteration\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Define colors for n_selections\n",
    "palette = {0: 'grey', 1: 'red', 2: 'blue'}\n",
    "\n",
    "for key, df in merged_group_dict.items():\n",
    "    # Filter out '_func_score_var' columns and select only '_func_score' columns\n",
    "    func_score_columns = [col for col in df.columns if col.endswith('_func_score') and not col.endswith('_func_score_var')]\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    df_clean = df.dropna(subset=func_score_columns)\n",
    "\n",
    "    # Separate DataFrame for WT and Variants\n",
    "    df_wt = df_clean[df_clean['n_aa_substitutions'] == 0]\n",
    "    df_variants = df_clean[df_clean['n_aa_substitutions'] > 0]\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    # Plot for WT\n",
    "    sns.regplot(x=func_score_columns[0], y=func_score_columns[1], data=df_wt, ax=axes[0], line_kws={'color': 'black'}, scatter_kws={'alpha': 0.5, 'color': 'grey'})\n",
    "    axes[0].set_title(f'WT Func Scores for {key}')\n",
    "    axes[0].set_xlabel(func_score_columns[0])\n",
    "    axes[0].set_ylabel(func_score_columns[1])\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot for Variants\n",
    "    sns.regplot(x=func_score_columns[0], y=func_score_columns[1], data=df_variants, ax=axes[1], line_kws={'color': 'black'}, scatter_kws={'alpha': 0.5, 'color': 'blue'})\n",
    "    axes[1].set_title(f'Variants Func Scores for {key}')\n",
    "    axes[1].set_xlabel(func_score_columns[0])\n",
    "    axes[1].set_ylabel(func_score_columns[1])\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Show or save the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Close the plot to avoid overlapping plots in the next iteration\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad12c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Define colors for n_selections\n",
    "palette = {0: 'grey', 1: 'red', 2: 'blue'}\n",
    "\n",
    "for key, df in merged_group_dict.items():\n",
    "    # Filter out '_func_score_var' columns and select only '_func_score' columns\n",
    "    func_score_columns = [col for col in df.columns if col.endswith('_func_score') and not col.endswith('_func_score_var')]\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    df_clean = df.dropna(subset=func_score_columns)\n",
    "\n",
    "    # Separate DataFrame for WT and Variants\n",
    "    df_wt = df_clean[df_clean['n_aa_substitutions'] == 0]\n",
    "    df_variants = df_clean[df_clean['n_aa_substitutions'] > 0]\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    # Plot for WT\n",
    "    sns.scatterplot(x=func_score_columns[0], y=func_score_columns[1], data=df_wt, hue='n_selections', palette=palette, ax=axes[0], alpha=0.5)\n",
    "    slope, intercept, r_value, _, _ = linregress(df_wt[func_score_columns[0]], df_wt[func_score_columns[1]])\n",
    "    axes[0].plot(df_wt[func_score_columns[0]], slope*df_wt[func_score_columns[0]] + intercept, color='black')\n",
    "    axes[0].set_title(f'WT Func Scores for {key}')\n",
    "    axes[0].set_xlabel(func_score_columns[0])\n",
    "    axes[0].set_ylabel(func_score_columns[1])\n",
    "    axes[0].grid(True)\n",
    "    # Annotate R^2 value\n",
    "    axes[0].text(0.7, 0.1, f'$R^2$: {r_value**2:.2f}', transform=axes[0].transAxes, fontsize=12, verticalalignment='top')\n",
    "\n",
    "    # Plot for Variants\n",
    "    sns.scatterplot(x=func_score_columns[0], y=func_score_columns[1], data=df_variants, hue='n_selections', palette=palette, ax=axes[1], alpha=0.5)\n",
    "    slope, intercept, r_value_var, _, _ = linregress(df_variants[func_score_columns[0]], df_variants[func_score_columns[1]])\n",
    "    axes[1].plot(df_variants[func_score_columns[0]], slope*df_variants[func_score_columns[0]] + intercept, color='black')\n",
    "    axes[1].set_title(f'Variants Func Scores for {key}')\n",
    "    axes[1].set_xlabel(func_score_columns[0])\n",
    "    axes[1].set_ylabel(func_score_columns[1])\n",
    "    axes[1].grid(True)\n",
    "    # Annotate R^2 value\n",
    "    axes[1].text(0.7, 0.1, f'$R^2$: {r_value_var**2:.2f}', transform=axes[1].transAxes, fontsize=12, verticalalignment='top')\n",
    "\n",
    "    # Adjust the legends\n",
    "    for ax, df_subset in zip(axes, [df_wt, df_variants]):\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        new_labels = []\n",
    "        for label in labels:\n",
    "            if label in ['0', '1', '2']:\n",
    "                n_sel = int(label)\n",
    "                percentage = (df_subset['n_selections'] == n_sel).mean() * 100\n",
    "                new_labels.append(f'n_selections {label} ({percentage:.1f}%)')\n",
    "            else:\n",
    "                new_labels.append(label)\n",
    "        ax.legend(handles, new_labels, title='n_selections', bbox_to_anchor=(0.05, 1), loc=2)\n",
    "\n",
    "    # Show or save the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Close the plot to avoid overlapping plots in the next iteration\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812fa75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count_histograms(df, key):\n",
    "    # Check if DataFrame contains all required n_selections values\n",
    "    if all(n in df['n_selections'].unique() for n in [0, 1, 2]):\n",
    "        # Identify DMSO_BxTx_count columns\n",
    "        dmso_count_cols = [col for col in df.columns if '_count' in col and 'DMSO' in col]\n",
    "\n",
    "        if len(dmso_count_cols) == 2:\n",
    "            \n",
    "            print(f\"Plotting for {key}...\")\n",
    "\n",
    "            # Initialize maximum frequency and define bins and colors\n",
    "            max_frequency, bins, colors = 0, 30, ['red', 'blue']\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # Create subplots\n",
    "\n",
    "            for i, n_sel in enumerate([0, 1, 2]):\n",
    "                df_filtered = df[df['n_selections'] == n_sel]\n",
    "                for col, color in zip(dmso_count_cols, colors):\n",
    "                    counts, bin_edges = np.histogram(df_filtered[col].dropna(), bins=bins)\n",
    "                    max_frequency = max(max_frequency, max(counts))\n",
    "\n",
    "                    sns.histplot(df_filtered[col], ax=axes[i], bins=bins, kde=False, alpha=0.5, color=color, label=col)\n",
    "\n",
    "                axes[i].set_yscale('log')\n",
    "                axes[i].set_title(f'(n_selections = {n_sel})')\n",
    "                axes[i].set_xlabel('Count')\n",
    "                axes[i].set_ylabel('Number of Barcodes' if i == 0 else '')\n",
    "                axes[i].legend()\n",
    "\n",
    "            for ax in axes:\n",
    "                ax.set_ylim(1, max_frequency * 1.5)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Expected two DMSO count columns, found {len(dmso_count_cols)}\")\n",
    "    else:\n",
    "        print(f\"Skipping {key} as it does not contain all n_selections values (0, 1, 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdf415",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# specific_key = '4u8c_B2T1-vs-DMSO_B1T2-and-4u8c_B2T2-vs-DMSO_B1T1'  # Replace this with the actual key you want to use\n",
    "\n",
    "# # Access the DataFrame using the key\n",
    "# specific_df = merged_group_dict[specific_key]\n",
    "\n",
    "# # Display the column names\n",
    "# print(specific_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d053e14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop through all DataFrames in merged_group_dict\n",
    "for key, df in merged_group_dict.items():\n",
    "    plot_count_histograms(df, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36369404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n_selections_plotting(df, threshold, non_dmso_count_cols):\n",
    "    df['n_selections'] = (df[non_dmso_count_cols] >= threshold).sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def plot_r2_vs_threshold(df, key, threshold):\n",
    "    thresholds = range(1, threshold)\n",
    "    r2_values = []\n",
    "\n",
    "    # Identify non-DMSO count columns and func_score columns\n",
    "    non_dmso_count_cols = [col for col in df.columns if '_count' in col and 'DMSO' not in col]\n",
    "    func_score_columns = [col for col in df.columns if col.endswith('_func_score') and not col.endswith('_func_score_var')]\n",
    "\n",
    "    # Ensure there are exactly 2 func_score columns to plot\n",
    "    if len(func_score_columns) == 2:\n",
    "        for threshold in thresholds:\n",
    "            df_threshold = calculate_n_selections_plotting(df.copy(), threshold, non_dmso_count_cols)\n",
    "            df_filtered = df_threshold[df_threshold['n_selections'] != 1]\n",
    "\n",
    "            if not df_filtered.empty:\n",
    "                slope, intercept, r_value, p_value, std_err = linregress(df_filtered[func_score_columns[0]], df_filtered[func_score_columns[1]])\n",
    "                r2_values.append(r_value**2)\n",
    "            else:\n",
    "                r2_values.append(np.nan)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(x=thresholds, y=r2_values)\n",
    "        plt.title('R² vs. Minimim barcode counts')\n",
    "        plt.title(f'{key}')\n",
    "        plt.xlabel('Minimum Barcode Counts')\n",
    "        plt.ylabel('R² Value')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Expected exactly 2 func_score columns.\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named 'df_example'\n",
    "# plot_r2_vs_threshold(df_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b00f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through all DataFrames in merged_group_dict\n",
    "for key, df in merged_group_dict.items():\n",
    "    plot_r2_vs_threshold(df,key,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming merged_group_dict is your dictionary of DataFrames\n",
    "# Replace 'example_key' with the actual key of the DataFrame you want to analyze\n",
    "df_example = merged_group_dict['4u8c_B2T1-vs-DMSO_B1T2-and-4u8c_B2T2-vs-DMSO_B1T1']\n",
    "\n",
    "def calculate_n_selections_optimized(df, threshold):\n",
    "    non_dmso_count_cols = [col for col in df.columns if '_count' in col and 'DMSO' not in col]\n",
    "    df['n_selections'] = (df[non_dmso_count_cols] >= threshold).sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def update_plot(threshold):\n",
    "    df_threshold = calculate_n_selections_optimized(df_example.copy(), threshold)\n",
    "    func_score_columns = [col for col in df_threshold.columns if col.endswith('_func_score') and not col.endswith('_func_score_var')]\n",
    "    \n",
    "    df_regression = df_threshold[df_threshold['n_selections'] != 1].dropna(subset=func_score_columns)\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(df_regression[func_score_columns[0]], df_regression[func_score_columns[1]])\n",
    "    regression_x = np.linspace(df_regression[func_score_columns[0]].min(), df_regression[func_score_columns[0]].max(), 100)\n",
    "    regression_y = regression_x * slope + intercept\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig = go.Figure()\n",
    "    for n_sel in sorted(df_threshold['n_selections'].unique()):\n",
    "        df_subset = df_threshold[df_threshold['n_selections'] == n_sel]\n",
    "        fig.add_trace(go.Scatter(x=df_subset[func_score_columns[0]], y=df_subset[func_score_columns[1]], mode='markers', \n",
    "                                 name=f'n_selections: {n_sel}', marker=dict(color=['grey', 'red', 'blue'][n_sel], size=10, opacity=0.5)))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=regression_x, y=regression_y, mode='lines', name='Regression Line', line=dict(color='black')))\n",
    "\n",
    "    fig.update_layout(title=f'Func Score Scatter Plot with Threshold {threshold} (R²: {r_value**2:.2f})',\n",
    "                      xaxis_title=func_score_columns[0], yaxis_title=func_score_columns[1],\n",
    "                      plot_bgcolor='white', showlegend=True, legend_title='Legend',\n",
    "                      xaxis=dict(showgrid=True, gridcolor='lightgrey', zeroline=False, linewidth=2, linecolor='black'),\n",
    "                      yaxis=dict(showgrid=True, gridcolor='lightgrey', zeroline=False, linewidth=2, linecolor='black'),\n",
    "                      width=1000, height=1000)\n",
    "    fig.show()\n",
    "\n",
    "# Create slider widget\n",
    "threshold_slider = widgets.IntSlider(min=1, max=25, step=1, value=20, description='Threshold', continuous_update=False)\n",
    "\n",
    "# Bind the slider to the update function\n",
    "widgets.interactive(update_plot, threshold=threshold_slider)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
