{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8412d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/keith_tetrad\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f4021a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('expand_frame_repr', False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f81a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509369b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "codon_variant = pd.read_csv('kw_dms/results/variants/codon_variants.csv', usecols=['barcode','library','barcode','codon_substitutions','aa_substitutions','n_codon_substitutions','n_aa_substitutions'])\n",
    "\n",
    "def calculate_functional_score(pre_selection, pre_selection_name, post_selection, post_selection_name, library, count_threshold):\n",
    "    # Rename count columns\n",
    "    pre_selection.rename(columns={'count': 'count_pre'}, inplace=True)\n",
    "    post_selection.rename(columns={'count': 'count_post'}, inplace=True)\n",
    "    \n",
    "    pre_selection = pre_selection[(pre_selection['count_pre'] >= count_threshold)] \n",
    "    \n",
    "    # Merge codon_variants with \n",
    "    pre_selection = pd.merge(pre_selection, codon_variant, on='barcode')\n",
    "    post_selection = pd.merge(post_selection, codon_variant, on='barcode')\n",
    "    \n",
    "    #filter out barcodes not in intended library\n",
    "    pre_selection = pre_selection[pre_selection['library'] == library]\n",
    "    post_selection = post_selection[post_selection['library'] == library]\n",
    "    \n",
    "    # Merge pre and post counts\n",
    "    merged_df = pd.merge(pre_selection, post_selection[['barcode', 'count_post']], on='barcode', how='left')\n",
    "    merged_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Change zeroes in 'count_post' to 0.5\n",
    "    # Convert 'count_post' column to float\n",
    "    merged_df['count_post'] = merged_df['count_post'].astype(float)\n",
    "\n",
    "    # Now change zeroes in 'count_post' to 0.5\n",
    "    merged_df.loc[merged_df['count_post'] == 0, 'count_post'] = 0.5\n",
    "    \n",
    "    # Calculate total wt counts then filter them out of the df\n",
    "    wt_barcodes = merged_df[merged_df['n_codon_substitutions'] == 0]\n",
    "    pre_wt_counts = wt_barcodes['count_pre'].sum()\n",
    "    post_wt_counts = wt_barcodes['count_post'].sum()\n",
    "    merged_df = merged_df[merged_df['n_codon_substitutions'] > 0]\n",
    "    \n",
    "    # Calculate the functional score for each row\n",
    "    merged_df['func_score'] = np.log2((merged_df['count_post'] / post_wt_counts) / (merged_df['count_pre'] / pre_wt_counts))\n",
    " \n",
    "    # Extract the specific parts of the names for renaming\n",
    "    pre_suffix = pre_selection_name.split('_')[1] if '_' in pre_selection_name else 'pre'\n",
    "    post_suffix = post_selection_name.split('_')[1] if '_' in post_selection_name else 'post'\n",
    "\n",
    "    # Rename count columns\n",
    "    merged_df.rename(columns={'count_pre': f'{pre_selection_name}_count'}, inplace=True)\n",
    "    merged_df.rename(columns={'count_post': f'{post_selection_name}_count'}, inplace=True)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8f0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_dataframes(dataframes_dict):\n",
    "#     merged_group_dict = {}\n",
    "\n",
    "#     # Create combinations of the keys (and their corresponding dataframes)\n",
    "#     for (key1, df1), (key2, df2) in combinations(dataframes_dict.items(), 2):\n",
    "#         # Rename 'func_score' and 'func_score_var' columns in df1 and df2\n",
    "#         df1_renamed = df1.rename(columns={\n",
    "#             'func_score': f'{key1}_func_score',\n",
    "#             'func_score_var': f'{key1}_func_score_var'\n",
    "#         })\n",
    "#         df2_renamed = df2.rename(columns={\n",
    "#             'func_score': f'{key2}_func_score',\n",
    "#             'func_score_var': f'{key2}_func_score_var'\n",
    "#         })\n",
    "\n",
    "#         # Merge DataFrames pairwise\n",
    "#         merged_df = pd.merge(df1_renamed, df2_renamed, on=['barcode', 'library', 'aa_substitutions', 'n_aa_substitutions','codon_substitutions', 'n_codon_substitutions'], how='outer')\n",
    "\n",
    "#         # Drop rows with NaNs in either of the func_score columns\n",
    "#         func_score_cols = [col for col in merged_df.columns if '_func_score' in col]\n",
    "#         merged_df.dropna(subset=func_score_cols, inplace=True)\n",
    "\n",
    "#         # Process duplicate '_count' columns\n",
    "#         count_columns_x = [col for col in merged_df.columns if col.endswith('_x') and '_count' in col]\n",
    "#         count_columns_y = [col for col in merged_df.columns if col.endswith('_y') and '_count' in col]\n",
    "\n",
    "#         for col_x, col_y in zip(count_columns_x, count_columns_y):\n",
    "#             base_col = col_x.replace('_x', '')\n",
    "#             merged_df[base_col] = merged_df[col_x].fillna(merged_df[col_y])\n",
    "#             merged_df.drop(columns=[col_x, col_y], inplace=True)\n",
    "\n",
    "#         # Store the merged DataFrame\n",
    "#         merged_group_dict[f'{key1}-and-{key2}'] = merged_df\n",
    "\n",
    "#     return merged_group_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c37e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(dataframes_dict):\n",
    "    merged_group_dict = {}\n",
    "\n",
    "    # Create combinations of the keys (and their corresponding dataframes)\n",
    "    for (key1, df1), (key2, df2) in combinations(dataframes_dict.items(), 2):\n",
    "        # Rename 'func_score' and 'func_score_var' columns in df1 and df2\n",
    "        df1_renamed = df1.rename(columns={\n",
    "            'func_score': f'{key1}_func_score',\n",
    "            'func_score_var': f'{key1}_func_score_var'\n",
    "        })\n",
    "        df2_renamed = df2.rename(columns={\n",
    "            'func_score': f'{key2}_func_score',\n",
    "            'func_score_var': f'{key2}_func_score_var'\n",
    "        })\n",
    "\n",
    "        # Merge DataFrames pairwise\n",
    "        merged_df = pd.merge(df1_renamed, df2_renamed, on=['barcode', 'library', 'aa_substitutions', 'n_aa_substitutions','codon_substitutions', 'n_codon_substitutions'], how='outer')\n",
    "\n",
    "        # Drop rows with NaNs in either of the func_score columns\n",
    "        func_score_cols = [col for col in merged_df.columns if '_func_score' in col]\n",
    "        merged_df.dropna(subset=func_score_cols, inplace=True)\n",
    "\n",
    "        # Process duplicate '_count' columns\n",
    "        count_columns_x = [col for col in merged_df.columns if col.endswith('_x') and '_count' in col]\n",
    "        count_columns_y = [col for col in merged_df.columns if col.endswith('_y') and '_count' in col]\n",
    "\n",
    "        for col_x, col_y in zip(count_columns_x, count_columns_y):\n",
    "            base_col = col_x.replace('_x', '')\n",
    "            merged_df[base_col] = merged_df[col_x].fillna(merged_df[col_y])\n",
    "            merged_df.drop(columns=[col_x, col_y], inplace=True)\n",
    "\n",
    "        # Calculate the average functional score\n",
    "        func_score_cols = [col for col in merged_df.columns if '_func_score' in col]\n",
    "        merged_df['func_score_avg'] = merged_df[func_score_cols].mean(axis=1)\n",
    "\n",
    "        # Sort by the average functional score\n",
    "        merged_df.sort_values(by='func_score_avg', ascending=True, inplace=True)\n",
    "        \n",
    "        # Reset index to get a new 'rank' column\n",
    "        merged_df.reset_index(drop=True, inplace=True)\n",
    "        merged_df['rank'] = merged_df.index\n",
    "        \n",
    "        # Store the merged DataFrame\n",
    "        merged_group_dict[f'{key1}-and-{key2}'] = merged_df\n",
    "\n",
    "    return merged_group_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09756661",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_DMSO_B1T1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-DMSO_bio1-1_counts.csv')\n",
    "sample_DMSO_B1T2 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-DMSO_bio1-2_counts.csv')\n",
    "sample_DMSO_B2T1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-DMSO_bio2-1_counts.csv')\n",
    "sample_DMSO_B2T2 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-DMSO_bio2-2_counts.csv')\n",
    "\n",
    "sample_control = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-DMSO_bio2-1_counts.csv')\n",
    "\n",
    "sample_4u8c_B1T1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-4u8c_bio1-1_counts.csv')\n",
    "sample_4u8c_B2T1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-4u8c_bio2-1_counts.csv')\n",
    "sample_4u8c_B2T2 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-4u8c_bio2-2_counts.csv')\n",
    "\n",
    "sample_C7_B1T2 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-C7_bio1-2_counts.csv')\n",
    "sample_C7_B2T1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-C7_bio2-1_counts.csv')\n",
    "\n",
    "sample_Both_B1T1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-Both_bio1-1_counts.csv')\n",
    "sample_Both_B2T1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-Both_bio2-1_counts.csv')\n",
    "\n",
    "func_scores_KW = {}\n",
    "func_scores_KW['4u8c_B1T1-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_4u8c_B1T1,'4u8c_B1T1','LibB',25)\n",
    "func_scores_KW['4u8c_B2T1-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_4u8c_B2T1,'4u8c_B2T1','LibB',25)\n",
    "func_scores_KW['4u8c_B2T2-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_4u8c_B2T2,'4u8c_B2T2','LibB',25)\n",
    "func_scores_KW['4u8c_B2T2-vs-DMSO_B2T2']=calculate_functional_score(sample_DMSO_B2T2,'DMSO_B2T2',sample_4u8c_B2T2,'4u8c_B2T2','LibB',25)\n",
    "\n",
    "func_scores_KW['C7_B1T2-vs-DMSO_B1T2']=calculate_functional_score(sample_DMSO_B1T2,'DMSO_B1T2',sample_C7_B1T2,'C7_B1T2','LibB',25)\n",
    "func_scores_KW['C7_B2T1-vs-DMSO_B2T1']=calculate_functional_score(sample_DMSO_B2T1,'DMSO_B2T1',sample_C7_B2T1,'C7_B2T1','LibB',25)\n",
    "\n",
    "func_scores_KW['Both_B1T1-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_Both_B1T1,'Both_B1T1','LibB',25)\n",
    "func_scores_KW['Both_B2T1-vs-DMSO_B2T1']=calculate_functional_score(sample_DMSO_B2T1,'DMSO_B2T1',sample_Both_B2T1,'Both_B2T1','LibB',25)\n",
    "\n",
    "func_score_comparisons_KW = merge_dataframes(func_scores_KW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d149c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1X_B1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-Spike_DMSO_bio1_1X-1_counts.csv')\n",
    "sample_5X_B1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-Spike_DMSO_bio1_5X-1_counts.csv')\n",
    "sample_10X_B1 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-Spike_DMSO_bio1_10X-1_counts.csv')\n",
    "\n",
    "sample_1X_B2 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-Spike_DMSO_bio2_1X-1_counts.csv')\n",
    "sample_5X_B2 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-Spike_DMSO_bio2_5X-1_counts.csv')\n",
    "sample_10X_B2 = pd.read_csv('kw_dms/old_results/barcode_counts/LibB-231017-Spike_DMSO_bio2_10X-1_counts.csv')\n",
    "\n",
    "func_scores_coverage = {}\n",
    "func_scores_coverage['DMSO_B2T1-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_control,'dmso_B2T1_control','LibB',25)\n",
    "func_scores_coverage['1X_B1-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_1X_B1,'1X_B1','LibB',25)\n",
    "func_scores_coverage['5X_B1-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_5X_B1,'5X_B1','LibB',25)\n",
    "func_scores_coverage['10X_B1-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_10X_B1,'10X_B1','LibB',25)\n",
    "func_scores_coverage['1X_B2-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_1X_B2,'1X_B2','LibB',25)\n",
    "func_scores_coverage['5X_B2-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_5X_B2,'5X_B2','LibB',25)\n",
    "func_scores_coverage['10X_B2-vs-DMSO_B1T1']=calculate_functional_score(sample_DMSO_B1T1,'DMSO_B1T1',sample_10X_B2,'10X_B2','LibB',25)\n",
    "\n",
    "\n",
    "func_score_comparisons_coverage = merge_dataframes(func_scores_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c7cb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['4u8c_B1T1-vs-DMSO_B1T1-and-4u8c_B2T1-vs-DMSO_B1T1', '4u8c_B1T1-vs-DMSO_B1T1-and-4u8c_B2T2-vs-DMSO_B1T1', '4u8c_B1T1-vs-DMSO_B1T1-and-4u8c_B2T2-vs-DMSO_B2T2', '4u8c_B1T1-vs-DMSO_B1T1-and-C7_B1T2-vs-DMSO_B1T2', '4u8c_B1T1-vs-DMSO_B1T1-and-C7_B2T1-vs-DMSO_B2T1', '4u8c_B1T1-vs-DMSO_B1T1-and-Both_B1T1-vs-DMSO_B1T1', '4u8c_B1T1-vs-DMSO_B1T1-and-Both_B2T1-vs-DMSO_B2T1', '4u8c_B2T1-vs-DMSO_B1T1-and-4u8c_B2T2-vs-DMSO_B1T1', '4u8c_B2T1-vs-DMSO_B1T1-and-4u8c_B2T2-vs-DMSO_B2T2', '4u8c_B2T1-vs-DMSO_B1T1-and-C7_B1T2-vs-DMSO_B1T2', '4u8c_B2T1-vs-DMSO_B1T1-and-C7_B2T1-vs-DMSO_B2T1', '4u8c_B2T1-vs-DMSO_B1T1-and-Both_B1T1-vs-DMSO_B1T1', '4u8c_B2T1-vs-DMSO_B1T1-and-Both_B2T1-vs-DMSO_B2T1', '4u8c_B2T2-vs-DMSO_B1T1-and-4u8c_B2T2-vs-DMSO_B2T2', '4u8c_B2T2-vs-DMSO_B1T1-and-C7_B1T2-vs-DMSO_B1T2', '4u8c_B2T2-vs-DMSO_B1T1-and-C7_B2T1-vs-DMSO_B2T1', '4u8c_B2T2-vs-DMSO_B1T1-and-Both_B1T1-vs-DMSO_B1T1', '4u8c_B2T2-vs-DMSO_B1T1-and-Both_B2T1-vs-DMSO_B2T1', '4u8c_B2T2-vs-DMSO_B2T2-and-C7_B1T2-vs-DMSO_B1T2', '4u8c_B2T2-vs-DMSO_B2T2-and-C7_B2T1-vs-DMSO_B2T1', '4u8c_B2T2-vs-DMSO_B2T2-and-Both_B1T1-vs-DMSO_B1T1', '4u8c_B2T2-vs-DMSO_B2T2-and-Both_B2T1-vs-DMSO_B2T1', 'C7_B1T2-vs-DMSO_B1T2-and-C7_B2T1-vs-DMSO_B2T1', 'C7_B1T2-vs-DMSO_B1T2-and-Both_B1T1-vs-DMSO_B1T1', 'C7_B1T2-vs-DMSO_B1T2-and-Both_B2T1-vs-DMSO_B2T1', 'C7_B2T1-vs-DMSO_B2T1-and-Both_B1T1-vs-DMSO_B1T1', 'C7_B2T1-vs-DMSO_B2T1-and-Both_B2T1-vs-DMSO_B2T1', 'Both_B1T1-vs-DMSO_B1T1-and-Both_B2T1-vs-DMSO_B2T1'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_score_comparisons_KW .keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a98720b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/w2n5lcb57zz70hk1l6tkkkf00000gp/T/ipykernel_63002/3636624033.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1.rename(columns={'func_score_avg': 'func_score_avg_4u8c'}, inplace=True)\n",
      "/var/folders/sv/w2n5lcb57zz70hk1l6tkkkf00000gp/T/ipykernel_63002/3636624033.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1.rename(columns={'rank': 'rank_4u8c'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "selected_key = '4u8c_B1T1-vs-DMSO_B1T1-and-4u8c_B2T2-vs-DMSO_B2T2'  # Replace with the actual key\n",
    "df_1 = func_score_comparisons_KW[selected_key]\n",
    "df_1 = df_1[['barcode', 'aa_substitutions', 'func_score_avg','rank']]\n",
    "df_1.rename(columns={'func_score_avg': 'func_score_avg_4u8c'}, inplace=True)\n",
    "df_1.rename(columns={'rank': 'rank_4u8c'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d99dfd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/w2n5lcb57zz70hk1l6tkkkf00000gp/T/ipykernel_63002/3354523991.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'func_score_avg': 'func_score_avg_C7'}, inplace=True)\n",
      "/var/folders/sv/w2n5lcb57zz70hk1l6tkkkf00000gp/T/ipykernel_63002/3354523991.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'rank': 'rank_C7'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "selected_key = 'C7_B1T2-vs-DMSO_B1T2-and-C7_B2T1-vs-DMSO_B2T1'  # Replace with the actual key\n",
    "df_2 = func_score_comparisons_KW[selected_key]\n",
    "df_2 = df_2[['barcode', 'aa_substitutions', 'func_score_avg','rank']]\n",
    "df_2.rename(columns={'func_score_avg': 'func_score_avg_C7'}, inplace=True)\n",
    "df_2.rename(columns={'rank': 'rank_C7'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cafa2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/w2n5lcb57zz70hk1l6tkkkf00000gp/T/ipykernel_63002/272840358.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3.rename(columns={'func_score_avg': 'func_score_avg_Both'}, inplace=True)\n",
      "/var/folders/sv/w2n5lcb57zz70hk1l6tkkkf00000gp/T/ipykernel_63002/272840358.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3.rename(columns={'rank': 'rank_Both'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "selected_key = 'Both_B1T1-vs-DMSO_B1T1-and-Both_B2T1-vs-DMSO_B2T1'  # Replace with the actual key\n",
    "df_3 = func_score_comparisons_KW[selected_key]\n",
    "df_3 = df_3[['barcode', 'aa_substitutions', 'func_score_avg','rank']]\n",
    "df_3.rename(columns={'func_score_avg': 'func_score_avg_Both'}, inplace=True)\n",
    "df_3.rename(columns={'rank': 'rank_Both'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2177d116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              barcode           aa_substitutions  rank_sum  rank_4u8c  rank_C7\n",
      "37   GTAGGAACAAGTCAAA                        P9R       257        225       32\n",
      "4    CCTAGAAACGCGTCTT                 D53G D140H       308         25      283\n",
      "28   CAGACAATCCCCGCTA                      K853F       309        194      115\n",
      "14   CAATATGAGAAGCGTA                      D250F       498         60      438\n",
      "89   CAATCTTAAAGGGATC                          0       633        586       47\n",
      "49   AACTTCGCAAATACCG           S13G T412S K966S       658        326      332\n",
      "76   AGAAGCTAACTAAGAA          R208- T247I V973G       659        526      133\n",
      "26   TTTGTGCCAGATGAGA               D250P T1114V       736        170      566\n",
      "51   ATTATGGCAGTAAGGC          F372I H502R Y793N       760        341      419\n",
      "104  AGTCAACGTCTAAAAT                T107I K676L       860        668      192\n",
      "131  CTAGCAAGTACGAGTG            F2S D140P D947V       905        823       82\n",
      "140  GCTCTCACGTAGAGTT                I99T N1131D      1016        841      175\n",
      "101  ACTTGACGTTTGAGGC  N143S T569C A1075V E1199K      1045        655      390\n",
      "9    CCATCACGGCAATATA                N231Y L449Q      1074         46     1028\n",
      "96   TGTGAAAAATTTAACA          M148W A219T I931M      1197        634      563\n",
      "198  ATAAAGTGCGGATCTT           T19P K145N D225Y      1238       1031      207\n",
      "191  TCAATCTCCGAGACCG     G73S T237I R495M Y498L      1249       1008      241\n",
      "31   ACATGAATGAAGTAAG                 I93G E616D      1354        204     1150\n",
      "73   GGGCTTTAGGGGAACA          V619Q S688Y P789L      1355        475      880\n",
      "152  ATTCCGGTGACATGTG  N183K D225H D1160R V1173P      1467        892      575\n"
     ]
    }
   ],
   "source": [
    "# Merge on common 'barcode' and 'aa_substitutions'\n",
    "common_barcodes = pd.merge(df_1, df_2, on=['barcode', 'aa_substitutions'], how='inner')\n",
    "\n",
    "# Identify rank columns (looking for columns that start with 'rank_')\n",
    "rank_cols = [col for col in common_barcodes.columns if col.startswith('rank_')]\n",
    "\n",
    "# Sum the ranks across the identified rank columns\n",
    "common_barcodes['rank_sum'] = common_barcodes[rank_cols].sum(axis=1)\n",
    "\n",
    "# Sort by the sum of ranks in ascending order\n",
    "common_barcodes.sort_values(by='rank_sum', ascending=True, inplace=True)\n",
    "\n",
    "# Print the top 20 records\n",
    "print(common_barcodes[['barcode', 'aa_substitutions', 'rank_sum','rank_4u8c','rank_C7']].head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e462e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              barcode          aa_substitutions  rank_sum  rank_4u8c  rank_Both\n",
      "30   TCACCACTCTCGTGAA               F152L W255C        86         85          1\n",
      "26   AAAGAACCACCACTGG               P80H P1087S       110         77         33\n",
      "40   CTGCTGTGCTAAGCAT   S69L D212A E987K R1088M       156        122         34\n",
      "24   CAATATGAGAAGCGTA                     D250F       167         60        107\n",
      "45   TTAACTTCGGTCGACT               D140G Y199H       190        136         54\n",
      "37   AATAAATGGGAGGATG                     A567G       272        114        158\n",
      "77   TCAGAACTTTCTAGCT               T29I R1016K       307        233         74\n",
      "82   ACCACTTTGAACGTCA        E164D K853N E1192G       385        247        138\n",
      "33   CTAACTGACCAGAATT               E209H K761M       454         97        357\n",
      "11   CCTAGAAACGCGTCTT                D53G D140H       472         25        447\n",
      "6    CCAATAAGCTCATAGT  D140H Q781L P806Q M1047L       539         15        524\n",
      "17   TTATATGACTGCAACA   D136H E164Q T713F Q932S       573         44        529\n",
      "100  AGTTCGAGCCACTCCA         F152Q D193Y P210L       582        316        266\n",
      "70   CATCTCCAACAGCAAA    N72T S110N A481S T615I       606        216        390\n",
      "66   ACATGAATGAAGTAAG                I93G E616D       622        204        418\n",
      "29   GTATGAACAACTAGTT                     Q577R       630         84        546\n",
      "139  AGTCAGCCTTGAAAAA               T122A N367S       634        461        173\n",
      "16   TAAATAGAGAATTCAT                     E209S       638         41        597\n",
      "123  AGACAACCAACCATCC                         0       639        397        242\n",
      "22   ATATTTTCACAGGGGT                    G1041D       692         56        636\n"
     ]
    }
   ],
   "source": [
    "# Merge on common 'barcode' and 'aa_substitutions'\n",
    "common_barcodes = pd.merge(df_1, df_3, on=['barcode', 'aa_substitutions'], how='inner')\n",
    "\n",
    "# Identify rank columns (looking for columns that start with 'rank_')\n",
    "rank_cols = [col for col in common_barcodes.columns if col.startswith('rank_')]\n",
    "\n",
    "# Sum the ranks across the identified rank columns\n",
    "common_barcodes['rank_sum'] = common_barcodes[rank_cols].sum(axis=1)\n",
    "\n",
    "# Sort by the sum of ranks in ascending order\n",
    "common_barcodes.sort_values(by='rank_sum', ascending=True, inplace=True)\n",
    "\n",
    "# Print the top 20 records\n",
    "print(common_barcodes[['barcode','aa_substitutions', 'rank_sum','rank_4u8c','rank_Both']].head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d906af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              barcode          aa_substitutions  rank_sum  rank_C7  rank_Both\n",
      "44   AGCTCGAATAGCAAGT                    D1160R       124      108         16\n",
      "6    TACGCATACTTCAGCC     R21I D78V R100G R270E       170       11        159\n",
      "79   AACTTAATATATTATG  S493I R495E G766V D1160Q       228      204         24\n",
      "9    CGCGATACTCTTTATT              E985K T1133Q       314       16        298\n",
      "50   CTTGATGATAAGATAA                     R405A       331      122        209\n",
      "63   CAAAAATCTCGCACTT                     N600K       334      158        176\n",
      "24   GAGAGCTAGTACCAAT             I1127V D1162G       373       52        321\n",
      "123  TATCCGCCCATAAAAA               E337K A842V       404      329         75\n",
      "103  AACTTCCCGGGCGTAA             A1053V M1234I       404      279        125\n",
      "46   TTATACTGTGTTTCGT                     E221N       441      113        328\n",
      "77   CAATAAACTAATAAAC                D78H A842Y       469      194        275\n",
      "142  TTGACCAGAGCTTGAA                         0       480      383         97\n",
      "149  ATGGTCACCAGGCTAA               Q52S R1011G       484      398         86\n",
      "154  TCCACCGCATATTCCT               D109H A843F       528      408        120\n",
      "110  TGTAAACCCTACTAAT         S96V G265S T1006I       538      300        238\n",
      "165  CAATATGAGAAGCGTA                     D250F       545      438        107\n",
      "65   ATATCAAAAAATAGAC        D173F Q674T L1060V       557      161        396\n",
      "88   TCAATCTCCGAGACCG    G73S T237I R495M Y498L       558      241        317\n",
      "193  TATTTAATCTCCATCA         A572V L846I R997S       602      500        102\n",
      "187  TGGACAAAATTACTCT    R76S D173A S511F V949I       644      490        154\n"
     ]
    }
   ],
   "source": [
    "# Merge on common 'barcode' and 'aa_substitutions'\n",
    "common_barcodes = pd.merge(df_2, df_3, on=['barcode', 'aa_substitutions'], how='inner')\n",
    "\n",
    "# Identify rank columns (looking for columns that start with 'rank_')\n",
    "rank_cols = [col for col in common_barcodes.columns if col.startswith('rank_')]\n",
    "\n",
    "# Sum the ranks across the identified rank columns\n",
    "common_barcodes['rank_sum'] = common_barcodes[rank_cols].sum(axis=1)\n",
    "\n",
    "# Sort by the sum of ranks in ascending order\n",
    "common_barcodes.sort_values(by='rank_sum', ascending=True, inplace=True)\n",
    "\n",
    "# Print the top 20 records\n",
    "print(common_barcodes[['barcode','aa_substitutions', 'rank_sum','rank_C7','rank_Both']].head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6baf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_noAB_B1 = pd.read_csv('SARS-CoV-2_Omicron_BA.1_spike_DMS_mAbs_kw/results/variant_counts/LibA_2022-04-13_thaw-1_no-antibody_control_1.csv', usecols=['barcode','count'])\n",
    "sample_noAB_B2 = pd.read_csv('SARS-CoV-2_Omicron_BA.1_spike_DMS_mAbs_kw/results/variant_counts/LibA_2022-04-13_thaw-1_no-antibody_control_2.csv', usecols=['barcode','count'])\n",
    "sample_LyCoV10_B1 = pd.read_csv('SARS-CoV-2_Omicron_BA.1_spike_DMS_mAbs_kw/results/variant_counts/LibA_2022-04-13_thaw-1_antibody_LyCoV-1404_10.464_1.csv', usecols=['barcode','count'])\n",
    "sample_LyCoV10_B2 = pd.read_csv('SARS-CoV-2_Omicron_BA.1_spike_DMS_mAbs_kw/results/variant_counts/LibA_2022-04-13_thaw-1_antibody_LyCoV-1404_10.464_2.csv', usecols=['barcode','count']) \n",
    "sample_LyCoV06_B1 = pd.read_csv('SARS-CoV-2_Omicron_BA.1_spike_DMS_mAbs_kw/results/variant_counts/LibA_2022-04-13_thaw-1_antibody_LyCoV-1404_0.654_1.csv', usecols=['barcode','count'])\n",
    "sample_LyCoV06_B2 = pd.read_csv('SARS-CoV-2_Omicron_BA.1_spike_DMS_mAbs_kw/results/variant_counts/LibA_2022-04-13_thaw-1_antibody_LyCoV-1404_0.654_2.csv', usecols=['barcode','count']) \n",
    "sample_LyCoV2_B1 = pd.read_csv('SARS-CoV-2_Omicron_BA.1_spike_DMS_mAbs_kw/results/variant_counts/LibA_2022-04-13_thaw-1_antibody_LyCoV-1404_2.616_1.csv', usecols=['barcode','count'])\n",
    "sample_LyCoV2_B2 = pd.read_csv('SARS-CoV-2_Omicron_BA.1_spike_DMS_mAbs_kw/results/variant_counts/LibA_2022-04-13_thaw-1_antibody_LyCoV-1404_2.616_2.csv', usecols=['barcode','count']) \n",
    "\n",
    "func_scores_BD = {}\n",
    "\n",
    "func_scores_BD['LyCoV10_B1-vs-noAB_B1'] = calculate_functional_score(sample_noAB_B1,'DMSO_B1',sample_LyCoV10_B1,'LyCoV10_B1','LibA',25)\n",
    "func_scores_BD['LyCoV10_B2-vs-noAB_B2'] = calculate_functional_score(sample_noAB_B2,'DMSO_B2',sample_LyCoV10_B2,'LyCoV10_B2','LibA',25)\n",
    "func_scores_BD['LyCoV06_B1-vs-noAB_B1'] = calculate_functional_score(sample_noAB_B1,'DMSO_B1',sample_LyCoV06_B1,'LyCoV06_B1','LibA',25)\n",
    "func_scores_BD['LyCoV06_B2-vs-noAB_B2'] = calculate_functional_score(sample_noAB_B2,'DMSO_B2',sample_LyCoV06_B2,'LyCoV06_B2','LibA',25)\n",
    "func_scores_BD['LyCoV2_B1-vs-noAB_B1'] = calculate_functional_score(sample_noAB_B1,'DMSO_B1',sample_LyCoV2_B1,'LyCoV2_B1','LibA',25)\n",
    "func_scores_BD['LyCoV2_B2-vs-noAB_B2'] = calculate_functional_score(sample_noAB_B2,'DMSO_B2',sample_LyCoV2_B2,'LyCoV2_B2','LibA',25)\n",
    "\n",
    "\n",
    "func_score_comparisons_BD = merge_dataframes(func_scores_BD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n_selections(df, threshold):\n",
    "    # Filter for non-DMSO count columns\n",
    "    non_dmso_count_cols = [col for col in df.columns if '_count' in col and 'DMSO' not in col]\n",
    "\n",
    "    # Use vectorized comparison and sum across rows\n",
    "    df['n_selections'] = (df[non_dmso_count_cols] >= threshold).sum(axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae51bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func_scores(dataframes_dict, key_to_plot):\n",
    "    sns.set(style='whitegrid')\n",
    "    palette = {0: 'grey', 1: 'red', 2: 'blue'}\n",
    "\n",
    "    df = dataframes_dict[key_to_plot]\n",
    "\n",
    "    # Filter out '_func_score_var' columns and select only '_func_score' columns\n",
    "    func_score_columns = [col for col in df.columns if col.endswith('_func_score') and not col.endswith('_func_score_var')]\n",
    "    \n",
    "    # Define a new column for point style based on n_aa_substitutions\n",
    "    df['style'] = df['n_aa_substitutions'].apply(lambda x: 'variant' if x > 0 else 'WT')\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    # Plot for all data\n",
    "    plot_scatter_and_regression(df, func_score_columns, axes[0], palette, 'All Data')\n",
    "\n",
    "    # Exclude n_selection = 1 and plot\n",
    "    df_excluded = df[df['n_selections'] != 1]\n",
    "    plot_scatter_and_regression(df_excluded, func_score_columns, axes[1], palette, 'Excluding n_selection = 1')\n",
    "\n",
    "    plt.suptitle(f'Linear Regression of Func Scores for {key_to_plot}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #plt.savefig(f'{key_to_plot}_func_scores_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_and_regression(df, func_score_columns, ax, palette, title):\n",
    "    df_clean = df.dropna(subset=func_score_columns)\n",
    "    sns.regplot(x=func_score_columns[0], y=func_score_columns[1], data=df_clean, line_kws={'color': 'black'}, scatter=False, ax=ax)\n",
    "    sns.scatterplot(x=func_score_columns[0], y=func_score_columns[1], data=df_clean, hue='n_selections', style='style', palette=palette, markers={'variant': 'X', 'WT': 'o'}, alpha=0.5, ax=ax)\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(df_clean[func_score_columns[0]], df_clean[func_score_columns[1]])\n",
    "    ax.annotate(f'$R^2$: {r_value**2:.2f}', xy=(0.05, 0.95), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "    ax.set_xlabel(func_score_columns[0])\n",
    "    ax.set_ylabel(func_score_columns[1])\n",
    "    ax.set_title(title)\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Adjust legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    n_selection_handles = handles[:len(palette)]\n",
    "    n_selection_labels = labels[:len(palette)]\n",
    "    style_handles = handles[len(palette):]\n",
    "    style_labels = labels[len(palette):]\n",
    "    ax.legend(n_selection_handles + style_handles, n_selection_labels + style_labels, title='n_selections & Style', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n_selections_plotting(df, threshold, non_dmso_count_cols):\n",
    "    df['n_selections'] = (df[non_dmso_count_cols] >= threshold).sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def plot_r2_vs_threshold(dataframes_dict, key, threshold):\n",
    "    thresholds = range(1, threshold)\n",
    "    r2_values = []\n",
    "    \n",
    "    df = dataframes_dict.get(key)\n",
    "\n",
    "    # Identify non-DMSO count columns and func_score columns\n",
    "    non_dmso_count_cols = [col for col in df.columns if '_count' in col and 'DMSO' not in col]\n",
    "    func_score_columns = [col for col in df.columns if col.endswith('_func_score') and not col.endswith('_func_score_var')]\n",
    "\n",
    "    # Ensure there are exactly 2 func_score columns to plot\n",
    "    if len(func_score_columns) == 2:\n",
    "        for threshold in thresholds:\n",
    "            df_threshold = calculate_n_selections_plotting(df.copy(), threshold, non_dmso_count_cols)\n",
    "            df_filtered = df_threshold[df_threshold['n_selections'] != 1]\n",
    "\n",
    "            if not df_filtered.empty:\n",
    "                slope, intercept, r_value, p_value, std_err = linregress(df_filtered[func_score_columns[0]], df_filtered[func_score_columns[1]])\n",
    "                r2_values.append(r_value**2)\n",
    "            else:\n",
    "                r2_values.append(np.nan)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(x=thresholds, y=r2_values)\n",
    "        plt.title('R² vs. Threshold Barcode Counts')\n",
    "        plt.title(f'{key}')\n",
    "        plt.xlabel('Threshold Barcode Counts')\n",
    "        plt.ylabel('R² Value')\n",
    "        \n",
    "        #plt.savefig(f'{key}_threshold_barcode_plot.png', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Expected exactly 2 func_score columns.\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named 'df_example'\n",
    "# plot_r2_vs_threshold(df_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edebd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_count_histograms(dataframes_dict, key):\n",
    "    df = dataframes_dict.get(key)\n",
    "    \n",
    "    sns.set(style='whitegrid')\n",
    "    \n",
    "    if df is not None:\n",
    "        if all(n in df['n_selections'].unique() for n in [0, 1, 2]):\n",
    "            dmso_count_cols = [col for col in df.columns if '_count' in col and 'DMSO' in col]\n",
    "\n",
    "            if 1 <= len(dmso_count_cols) <= 2:\n",
    "                print(f\"DMSO Barcode Count Frequency For {key}\")\n",
    "\n",
    "                max_frequency, bins, colors = 0, 30, ['red', 'blue']\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "                # Calculate the total barcodes for each DMSO count column\n",
    "                total_barcodes = {col: df[col].sum() for col in dmso_count_cols}\n",
    "\n",
    "                for i, n_sel in enumerate([0, 1, 2]):\n",
    "                    df_filtered = df[df['n_selections'] == n_sel]\n",
    "                    legend_labels = []\n",
    "\n",
    "                    for col, color in zip(dmso_count_cols, colors):\n",
    "                        counts, bin_edges = np.histogram(df_filtered[col].dropna(), bins=bins)\n",
    "                        max_frequency = max(max_frequency, max(counts))\n",
    "\n",
    "                        sns.histplot(df_filtered[col], ax=axes[i], bins=bins, kde=False, alpha=0.5, color=color)\n",
    "\n",
    "                        # Calculate and format the percentage for the legend\n",
    "                        percentage = (df_filtered[col].sum() / total_barcodes[col]) * 100\n",
    "                        legend_label = f'{col} ({percentage:.2f}%)'\n",
    "                        legend_labels.append(legend_label)\n",
    "\n",
    "                    axes[i].set_yscale('log')\n",
    "                    axes[i].set_title(f'(n_selections = {n_sel})')\n",
    "                    axes[i].set_xlabel('Count')\n",
    "                    axes[i].set_ylabel('Number of Barcodes' if i == 0 else '')\n",
    "                    axes[i].legend(labels=legend_labels)\n",
    "\n",
    "                for ax in axes:\n",
    "                    ax.set_ylim(1, max_frequency * 1.5)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                #plt.savefig(f'{key}_histograms_plot.png', dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Expected 1 or 2 DMSO count columns, found {len(dmso_count_cols)}\")\n",
    "        else:\n",
    "            print(f\"Skipping {key} as it does not contain all n_selections values (0, 1, 2)\")\n",
    "    else:\n",
    "        print(f\"No DataFrame found for key '{key}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a73973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func_score_comparisons_coverage.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4bd06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_r2_vs_threshold(func_score_comparisons_coverage, '5X_B2-vs-DMSO_B1T1-and-10X_B2-vs-DMSO_B1T1',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in func_score_comparisons_coverage:\n",
    "    func_score_comparisons_coverage[key] = calculate_n_selections(func_score_comparisons_coverage[key], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c86177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_count_histograms(func_score_comparisons_coverage, '1X_B1-vs-DMSO_B1T1-and-10X_B1-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7217fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_count_histograms(func_score_comparisons_coverage, '5X_B1-vs-DMSO_B1T1-and-10X_B1-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_histograms(func_score_comparisons_coverage, '10X_B1-vs-DMSO_B1T1-and-10X_B2-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b79e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_func_scores(func_score_comparisons_coverage, '1X_B1-vs-DMSO_B1T1-and-1X_B2-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c772d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_func_scores(func_score_comparisons_coverage, '5X_B1-vs-DMSO_B1T1-and-10X_B1-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfe011",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_func_scores(func_score_comparisons_coverage, 'DMSO_B2T1-vs-DMSO_B1T1-and-10X_B1-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450196d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_count_histograms(func_score_comparisons_coverage, '1X_B2-vs-DMSO_B1T1-and-10X_B2-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b1099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_count_histograms(func_score_comparisons_coverage, '5X_B2-vs-DMSO_B1T1-and-10X_B2-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_histograms(func_score_comparisons_coverage, 'DMSO_B2T1-vs-DMSO_B1T1-and-10X_B2-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ac1d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_func_scores(func_score_comparisons_coverage, '1X_B2-vs-DMSO_B1T1-and-10X_B2-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_func_scores(func_score_comparisons_coverage, '5X_B2-vs-DMSO_B1T1-and-10X_B2-vs-DMSO_B1T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a02119",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_func_scores(func_score_comparisons_coverage, 'DMSO_B2T1-vs-DMSO_B1T1-and-10X_B2-vs-DMSO_B1T1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
